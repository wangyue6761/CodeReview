"""‰ª£Á†ÅÂÆ°Êü•Â∑•‰ΩúÊµÅÁöÑÊÑèÂõæÂàÜÊûêËäÇÁÇπ„ÄÇ

ÂÆûÁé∞ Map-Reduce Ê®°ÂºèÔºåÂπ∂Ë°åÂàÜÊûêÂèòÊõ¥Êñá‰ª∂ÁöÑÊÑèÂõæ„ÄÇ
‰ΩøÁî® LCEL ËØ≠Ê≥ïÔºöprompt | llm | parser„ÄÇ
"""

import asyncio
import logging
import json
import re
import os
from typing import Dict, Any
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.language_models import BaseChatModel
from core.state import ReviewState, FileAnalysis, RiskItem, RiskType
from agents.prompts import render_prompt_template
from util.diff_utils import generate_context_text_for_file, extract_file_diff
from util.file_utils import read_file_content
from util.json_utils import extract_json_from_text
from util.runtime_utils import elapsed_tag

logger = logging.getLogger(__name__)

def _normalize_line_number(v: Any) -> Any:
    """Best-effort normalization to [start, end] for RiskItem parsing."""
    if v is None:
        return None
    if isinstance(v, int):
        return [int(v), int(v)]
    if isinstance(v, str):
        s = v.strip()
        if s.isdigit():
            n = int(s)
            return [n, n]
    if isinstance(v, (list, tuple)):
        if len(v) == 1:
            n = int(v[0])
            return [n, n]
        if len(v) == 2:
            return [int(v[0]), int(v[1])]
    return None


async def intent_analysis_node(state: ReviewState) -> Dict[str, Any]:
    """Âπ∂Ë°åÂàÜÊûêÊâÄÊúâÂèòÊõ¥Êñá‰ª∂ÁöÑÊÑèÂõæÔºàMap-Reduce Ê®°ÂºèÔºâ„ÄÇ
    
    Returns:
        ÂåÖÂê´ 'file_analyses' ÈîÆÁöÑÂ≠óÂÖ∏„ÄÇ
    """
    print("\n" + "="*80)
    meta = state.get("metadata") or {}
    print(f"üìã [ËäÇÁÇπ1] Intent Analysis - Âπ∂Ë°åÂàÜÊûêÊñá‰ª∂ÊÑèÂõæ ({elapsed_tag(meta)})")
    print("="*80)
    
    # Get LLM from metadata (injected by workflow)
    llm: BaseChatModel = state.get("metadata", {}).get("llm")
    if not llm:
        logger.error("LLM not found in metadata")
        return {"file_analyses": []}
    
    # Get config for concurrency control
    config = state.get("metadata", {}).get("config")
    max_concurrent = config.system.max_concurrent_llm_requests if config else 5
    
    changed_files = state.get("changed_files", [])
    if not changed_files:
        print("  ‚ö†Ô∏è  Ê≤°ÊúâÈúÄË¶ÅÂàÜÊûêÁöÑÊñá‰ª∂")
        logger.warning("No changed files to analyze")
        return {"file_analyses": []}
    
    # ===== ‰∏¥Êó∂Ë∞ÉËØïÔºöÊñá‰ª∂ËøáÊª§ =====
    # TODO: Ë∞ÉËØïÂÆåÊàêÂêéÂà†Èô§Ê≠§‰ª£Á†ÅÂùó
    # ËØ¥ÊòéÔºöÈªòËÆ§‰∏çÂêØÁî®ËøáÊª§ÔºàÈÅøÂÖçÂΩ±Âìç benchmarkÔºâ„ÄÇÈúÄË¶ÅË∞ÉËØïÊó∂ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö
    #   export INTENT_ANALYSIS_TARGET_FILE="path/to/file.py"
    target_file = os.environ.get("INTENT_ANALYSIS_TARGET_FILE", "").strip()
    if target_file:
        changed_files = [f for f in changed_files if f == target_file or f.endswith(target_file)]
        if changed_files:
            print(f"  üîç [Ë∞ÉËØïÊ®°Âºè] ËøáÊª§ÂêéÂè™ÂàÜÊûêÊñá‰ª∂: {changed_files}")
        else:
            print(f"  ‚ö†Ô∏è  [Ë∞ÉËØïÊ®°Âºè] ÁõÆÊ†áÊñá‰ª∂ '{target_file}' ‰∏çÂú®ÂèòÊõ¥ÂàóË°®‰∏≠")
            return {"file_analyses": []}
    # ===== ‰∏¥Êó∂Ë∞ÉËØï‰ª£Á†ÅÁªìÊùü =====
    
    print(f"  üìÅ ÂæÖÂàÜÊûêÊñá‰ª∂Êï∞: {len(changed_files)}")
    print(f"  üîí Âπ∂ÂèëÊéßÂà∂: Semaphore(max={max_concurrent})")
    print(f"  üìù Êñá‰ª∂ÂàóË°®:")
    for i, file_path in enumerate(changed_files, 1):
        print(f"     {i}. {file_path}")
    
    diff_context = state.get("diff_context", "")
    
    # Create semaphore for concurrency control
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def analyze_file(file_path: str) -> FileAnalysis:
        """‰ΩøÁî® LCEL ËØ≠Ê≥ïÂàÜÊûêÂçï‰∏™Êñá‰ª∂„ÄÇ"""
        async with semaphore:
            try:
                print(f"  üîç ÂàÜÊûê‰∏≠: {file_path}")
                file_diff = extract_file_diff(diff_context, file_path)
                
                # ËØªÂèñÊñá‰ª∂ÂÜÖÂÆπ
                file_content = read_file_content(file_path, config)
                
                # Ê∏≤ÊüìÊèêÁ§∫Ê®°Êùø
                rendered_prompt = render_prompt_template(
                    "intent_analysis",
                    file_path=file_path,
                    file_diff=file_diff,
                    file_content=file_content
                )
                
                parser = PydanticOutputParser(pydantic_object=FileAnalysis)
                
                # ÂàõÂª∫Ê∂àÊÅØÂàóË°®ÔºàÁõ¥Êé•‰ΩøÁî®Â∑≤Ê∏≤ÊüìÁöÑÊñáÊú¨ÔºåÂπ∂Ê∑ªÂä†Ê†ºÂºèËØ¥ÊòéÔºâ
                messages = [
                    SystemMessage(content="You are an expert code reviewer analyzing file changes."),
                    HumanMessage(content=rendered_prompt + "\n\n" + parser.get_format_instructions())
                ]
                
                # ‰ΩøÁî® LCEL ËØ≠Ê≥ïÔºömessages -> llm -> parser
                response_text = ""
                try:
                    # Avoid per-call temperature overrides for provider compat; rely on model config.
                    response = await llm.ainvoke(messages)
                    response_text = response.content if hasattr(response, "content") else str(response)
                except Exception as e:
                    # LLM Ë∞ÉÁî®Â§±Ë¥•ÔºöÂõûÈÄÄÂà∞ÊñáÊú¨Ëß£ÊûêÔºàÈÄöÂ∏∏‰∏∫ provider ÈîôËØØ/‰ΩôÈ¢ù‰∏çË∂≥Á≠âÔºâ
                    logger.warning(
                        f"LLM invoke failed for {file_path}, falling back to text parsing: "
                        f"{type(e).__name__}: {e!r}"
                    )
                    response_text = str(e) if str(e) else type(e).__name__

                try:
                    # Some providers/models may wrap JSON in markdown or add preamble; extract JSON first.
                    json_text = extract_json_from_text(response_text) or response_text
                    file_analysis: FileAnalysis = parser.parse(json_text)
                except Exception as e:
                    # Ëß£ÊûêÂ§±Ë¥•ÔºöÂõûÈÄÄÂà∞ÊñáÊú¨Ëß£Êûê
                    logger.warning(f"PydanticOutputParser failed for {file_path}, falling back to text parsing: {e}")
                    file_analysis = _parse_intent_analysis_response(response_text, file_path)
                
                print(f"  ‚úÖ ÂÆåÊàê: {file_path}")
                print(f"     ÊÑèÂõæÊëòË¶Å: {file_analysis.intent_summary[:80]}...")
                print(f"     ÊΩúÂú®È£éÈô©Êï∞: {len(file_analysis.potential_risks)}")
                logger.info(f"Analyzed intent for {file_path}: {file_analysis.intent_summary[:100]}...")
                return file_analysis
            except Exception as e:
                logger.error(f"Error analyzing intent for {file_path}: {e}")
                # Return error analysis
                return FileAnalysis(
                    file_path=file_path,
                    intent_summary=f"Error analyzing file: {str(e)}",
                    potential_risks=[],
                    complexity_score=None
                )
    
    # Process all files concurrently
    print(f"\n  üöÄ ÂºÄÂßãÂπ∂Ë°åÂàÜÊûê {len(changed_files)} ‰∏™Êñá‰ª∂...")
    file_analyses = await asyncio.gather(*[analyze_file(f) for f in changed_files])
    
    # Convert Pydantic models to dicts for state (LangGraph TypedDict compatibility)
    file_analyses_dicts = [fa.model_dump() for fa in file_analyses]
    
    total_risks = sum(len(fa.potential_risks) for fa in file_analyses)
    print(f"\n  ‚úÖ Intent Analysis ÂÆåÊàê! ({elapsed_tag(meta)})")
    print(f"     - ÂàÜÊûêÊñá‰ª∂Êï∞: {len(file_analyses)}")
    print(f"     - ÂèëÁé∞ÊΩúÂú®È£éÈô©: {total_risks} ‰∏™")
    print("="*80)
    logger.info(f"Completed intent analysis for {len(file_analyses)} files")

    
    return {
        "file_analyses": file_analyses_dicts
    }


def _parse_intent_analysis_response(response: str, file_path: str) -> FileAnalysis:
    """Ëß£Êûê LLM ÂìçÂ∫î‰∏∫ FileAnalysis ÂØπË±°ÔºàPydanticOutputParser Â§±Ë¥•Êó∂ÁöÑÂõûÈÄÄÊñπÊ°àÔºâ„ÄÇ"""
    try:
        try:
            json_text = extract_json_from_text(response) or ""
            data = json.loads(json_text) if json_text else {}
            intent_summary = data.get("intent_summary", response[:500])
            potential_risks_data = data.get("potential_risks", [])
            complexity_score = data.get("complexity_score")
            
            # Convert potential_risks to RiskItem objects
            potential_risks = []
            for risk_data in potential_risks_data:
                try:
                    line_number = _normalize_line_number(risk_data.get("line_number"))
                    if line_number is None:
                        logger.error(f"Missing line_number in risk item: {risk_data}, file_path: {file_path}")
                        continue
                    
                    risk_item = RiskItem(
                        risk_type=risk_data.get("risk_type", RiskType.ROBUSTNESS_BOUNDARY_CONDITIONS.value),
                        file_path=risk_data.get("file_path", file_path),
                        line_number=line_number,
                        description=risk_data.get("description", ""),
                        confidence=risk_data.get("confidence", 0.5),
                        severity=risk_data.get("severity", "info"),
                        suggestion=risk_data.get("suggestion")
                    )
                    potential_risks.append(risk_item)
                except Exception as e:
                    logger.error(f"Failed to parse risk item: {e}, risk_data: {risk_data}, file_path: {file_path}")
                    continue
            
            return FileAnalysis(
                file_path=file_path,
                intent_summary=intent_summary,
                potential_risks=potential_risks,
                complexity_score=complexity_score
            )
        except Exception:
            # If JSON parsing fails, create a simple FileAnalysis from text
            return FileAnalysis(
                file_path=file_path,
                intent_summary=response[:500],
                potential_risks=[],
                complexity_score=None
            )
    except Exception as e:
        logger.error(f"Error parsing intent analysis response: {e}")
        return FileAnalysis(
            file_path=file_path,
            intent_summary=f"Error parsing response: {str(e)}",
            potential_risks=[],
            complexity_score=None
        )
