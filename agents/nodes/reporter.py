"""ä»£ç å®¡æŸ¥å·¥ä½œæµçš„æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹ã€‚

èšåˆä¸“å®¶ç»“æœå¹¶åº”ç”¨ç½®ä¿¡åº¦è¿‡æ»¤ï¼Œç”Ÿæˆæœ€ç»ˆå®¡æŸ¥æŠ¥å‘Šã€‚
"""

import logging
from typing import Dict, Any, List
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.language_models import BaseChatModel
from core.state import ReviewState, RiskItem
from agents.prompts import render_prompt_template
from util.runtime_utils import elapsed_tag

logger = logging.getLogger(__name__)


async def reporter_node(state: ReviewState) -> Dict[str, Any]:
    """ä»ä¸“å®¶ç»“æœç”Ÿæˆæœ€ç»ˆå®¡æŸ¥æŠ¥å‘Šã€‚
    
    Returns:
        åŒ…å« 'confirmed_issues' å’Œ 'final_report' é”®çš„å­—å…¸ã€‚
    """
    print("\n" + "="*80)
    meta = state.get("metadata") or {}
    print(f"ğŸ“Š [èŠ‚ç‚¹4] Reporter - ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ({elapsed_tag(meta)})")
    print("="*80)
    
    # Get LLM from metadata
    llm: BaseChatModel = state.get("metadata", {}).get("llm")
    if not llm:
        logger.error("LLM not found in metadata")
        return {"confirmed_issues": [], "final_report": "é”™è¯¯ï¼šLLM ä¸å¯ç”¨"}
    
    expert_results_dicts = state.get("expert_results", {})
    diff_context = state.get("diff_context", "")
    
    # Convert dicts to Pydantic models for processing
    from core.state import RiskItem
    expert_results = {
        risk_type: [RiskItem(**item) if isinstance(item, dict) else item for item in items]
        for risk_type, items in expert_results_dicts.items()
    }
    
    # Collect all results from expert groups
    all_results: List[RiskItem] = []
    for risk_type_str, results in expert_results.items():
        all_results.extend(results)
    
    print(f"  ğŸ“¥ æ”¶é›†ä¸“å®¶ç»“æœ: {len(all_results)} ä¸ª")
    
    # Filter by confidence threshold (default: 0.5)
    confidence_threshold = state.get("metadata", {}).get("confidence_threshold", 0.5)
    config = state.get("metadata", {}).get("config")
    threshold_by_type = {}
    try:
        threshold_by_type = dict(getattr(getattr(config, "system", None), "confidence_threshold_by_risk_type", {}) or {})
    except Exception:
        threshold_by_type = {}

    confirmed_issues = [
        item for item in all_results
        if item.confidence >= float(threshold_by_type.get(item.risk_type.value, confidence_threshold))
    ]
    
    print(f"  ğŸ” æŒ‰ç½®ä¿¡åº¦è¿‡æ»¤ (é˜ˆå€¼: {confidence_threshold})")
    print(f"     - æ€»ç»“æœæ•°: {len(all_results)}")
    print(f"     - ç¡®è®¤é—®é¢˜æ•°: {len(confirmed_issues)}")
    
    logger.info(f"Reporter: {len(all_results)} total results, "
                f"{len(confirmed_issues)} confirmed issues (threshold: {confidence_threshold})")

    if not confirmed_issues:
        final_report = _generate_simple_report([])
        confirmed_issues_dicts: List[Dict[str, Any]] = []
        return {
            "confirmed_issues": confirmed_issues_dicts,
            "final_report": final_report,
        }

    try:
        # Generate final report
        print("  ğŸ¤– è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        prompt = render_prompt_template(
            "reporter",
            diff_context=diff_context[:3000],  # Limit context size
            confirmed_issues=[item.model_dump() for item in confirmed_issues],
            num_issues=len(confirmed_issues),
            num_files=len(state.get("changed_files", []))
        )
        
        # Use standard ChatModel interface
        messages = [
            SystemMessage(content="ä½ æ˜¯ä»£ç å®¡æŸ¥ä¸“å®¶ï¼Œè¯·ç”¨ä¸­æ–‡è¾“å‡ºæœ€ç»ˆå®¡æŸ¥æŠ¥å‘Šã€‚"),
            HumanMessage(content=prompt)
        ]
        response = await llm.ainvoke(messages)
        final_report = response.content if hasattr(response, 'content') else str(response)
        
        print(f"  âœ… Reporter å®Œæˆ! ({elapsed_tag(meta)})")
        print(f"     - æŠ¥å‘Šé•¿åº¦: {len(final_report)} å­—ç¬¦")
        print(f"     - ç¡®è®¤é—®é¢˜: {len(confirmed_issues)} ä¸ª")
        print("="*80)
        logger.info(f"Generated final report: {len(final_report)} characters")
        
        # Convert Pydantic models to dicts for state (LangGraph TypedDict compatibility)
        confirmed_issues_dicts = [item.model_dump() for item in confirmed_issues]
        
        return {
            "confirmed_issues": confirmed_issues_dicts,
            "final_report": final_report
        }
    except Exception as e:
        logger.error(f"Error generating report: {e}")
        # Generate simple report from confirmed issues
        simple_report = _generate_simple_report(confirmed_issues)
        return {
            "confirmed_issues": confirmed_issues,
            "final_report": simple_report
        }


def _generate_simple_report(confirmed_issues: List[RiskItem]) -> str:
    """ä»ç¡®è®¤çš„é—®é¢˜ç”Ÿæˆç®€å•æ–‡æœ¬æŠ¥å‘Šã€‚"""
    if not confirmed_issues:
        return "æœªå‘ç°é—®é¢˜ï¼Œä»£ç å®¡æŸ¥å·²å®Œæˆã€‚"
    
    report_lines = [
        "# ä»£ç å®¡æŸ¥æŠ¥å‘Š",
        f"\né—®é¢˜æ€»æ•°: {len(confirmed_issues)}\n",
        "## æŒ‰ä¸¥é‡çº§åˆ«åˆ†ç±»\n"
    ]
    
    # Group by severity
    by_severity = {}
    for issue in confirmed_issues:
        severity = issue.severity
        if severity not in by_severity:
            by_severity[severity] = []
        by_severity[severity].append(issue)
    
    for severity in ["error", "warning", "info"]:
        if severity in by_severity:
            report_lines.append(f"\n### {severity.upper()}ï¼ˆ{len(by_severity[severity])}ï¼‰")
            for issue in by_severity[severity]:
                # Format line number range: (10, 15) -> "10:15", (10, 10) -> "10"
                start_line, end_line = issue.line_number
                if start_line == end_line:
                    line_str = str(start_line)
                else:
                    line_str = f"{start_line}:{end_line}"
                
                report_lines.append(
                    f"- **{issue.file_path}:{line_str}** "
                    f"[{issue.risk_type.value}] "
                    f"(confidence: {issue.confidence:.2f})\n"
                    f"  {issue.description}"
                )
                if issue.suggestion:
                    report_lines.append(f"  ğŸ’¡ å»ºè®®: {issue.suggestion}")
    
    return "\n".join(report_lines)
